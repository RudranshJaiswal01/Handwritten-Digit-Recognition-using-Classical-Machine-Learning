# ğŸ§  Handwritten Digit Recognition using Classical Machine Learning  
**Virtualyyst AI Assignment Submission**

---

## ğŸ“Œ Overview

This repository contains my submission for the **Virtualyyst AI Assignment: Handwritten Digit Recognition**.  
The goal of the assignment is to build an end-to-end machine learning pipeline to classify handwritten digit images (0â€“9) using **classical machine learning techniques**, without using neural networks or pre-trained models.

The implementation is fully contained in a single executed Jupyter notebook and focuses on:
- Understanding image data in tabular (CSV) form
- Implementing and evaluating classical ML models
- Clearly explaining design decisions and limitations

---

## ğŸ“‚ Dataset

- **Dataset**: MNIST subset in CSV format
- **Structure**:
  - `label` â†’ digit class (0â€“9)
  - `pixel0` to `pixel783` â†’ flattened 28Ã—28 grayscale image pixels
- Pixel values range from **0 to 255**

---

## ğŸ§ª Workflow Summary

### 1ï¸âƒ£ Data Loading & Exploration
- Dataset loaded using **Pandas**
- Verified:
  - Dataset shape
  - Class distribution
  - Absence of missing values
- Sample images visualized by reshaping rows into **28Ã—28** matrices

---

### 2ï¸âƒ£ Preprocessing
- Pixel values normalized to the range **[0, 1]**
- Dataset split into **training and testing sets (80/20)**

---

## ğŸ¤– Model Implementations

### ğŸ”¹ K-Nearest Neighbors (KNN) â€” *From Scratch*
- Implemented **manually without using scikit-learn**
- Euclidean distanceâ€“based neighbor search
- Due to high computational cost, evaluation was performed on a **subset of 300 test samples**
- Achieved ~**98% accuracy on this subset**

#### Important Notes:
- This evaluation is **not representative of full test-set performance**
- KNN was tested primarily to **validate correctness of the from-scratch implementation**
- **No confusion matrix was generated** for KNN, as the subset size was intentionally limited

---

### ğŸ”¹ Support Vector Machine (SVM)
- Implemented using **scikit-learn**
- **Linear kernel** was used

#### Why Linear SVM?
- The dataset is high-dimensional (784 features)
- RBF kernel would require:
  - Much higher computational cost
  - Dimensionality reduction (e.g., PCA) for feasibility
- Linear SVM provided a strong balance between performance and efficiency

---

### ğŸ”¹ Decision Tree
- Implemented using **scikit-learn**
- Tuned parameters such as:
  - `max_depth`
  - `min_samples_split`
- Used to compare interpretability vs generalization performance

---

## ğŸ“Š Model Evaluation

- **Accuracy** computed for all evaluated models
- **Confusion matrices generated only for:**
  - Linear SVM
  - Decision Tree
- Confusion matrices visualized using heatmaps
- Misclassified samples were inspected to understand error patterns

---

## ğŸ“ˆ Model Comparison & Analysis

- **Linear SVM** achieved the best overall performance on the full test set
- **Decision Tree** showed reasonable accuracy but signs of overfitting
- **KNN (from scratch)** demonstrated strong performance on a small subset but is computationally impractical at scale

### Observed Misclassifications:
- Visually similar digits (e.g., 4 vs 9, 3 vs 5)
- Variations in handwriting style and stroke thickness

---

## ğŸ§© Flow Diagram

A **flow diagram** is included in the notebook that outlines:
- Data loading
- Preprocessing
- Model training
- Evaluation steps

<img width="501" height="513" alt="Flow diagram" src="https://github.com/user-attachments/assets/8fa07d9f-7d9f-4992-9cc2-d47aae71e3d4" />

This satisfies the technical execution flow requirement of the assignment.

---

## ğŸ›  Tools & Libraries Used

- Python  
- NumPy  
- Pandas  
- scikit-learn  
- Matplotlib / Seaborn  

---

## ğŸš« Constraints Followed

- âŒ No neural networks  
- âŒ No pre-trained models  
- âŒ No LLMs or managed cloud platforms  
- âœ… Classical ML only  
- âœ… One model implemented from scratch  

---

## ğŸ“Œ Submission Notes

- All notebook cells are **executed**
- Code includes **inline comments and markdown explanations**
- Outputs, plots, and visualizations are visible
- Explanations reflect **actual implementation decisions and limitations**

---

## ğŸ‘¤ Author

**Rudransh Jaiswal**  
